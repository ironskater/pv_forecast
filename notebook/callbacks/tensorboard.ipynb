{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: A 1D convnet on the IMDB sentiment-analysis task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "/home/iot/miniconda3/envs/pv_forecast/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/home/iot/miniconda3/envs/pv_forecast/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         [(None, None)]            0         \n",
      "_________________________________________________________________\n",
      "embed (Embedding)            (None, None, 128)         256000    \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 32)          28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 32)          7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "\n",
    "max_features = 2000 # number of words to consider as features\n",
    "max_len = 500 # cuts off texts after this number of words(among max_features most common words)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = sequence.pad_sequences(x_test, maxlen=max_len)\n",
    "\n",
    "text_input = Input(shape=(None,))\n",
    "x = layers.Embedding(   input_dim=max_features, \n",
    "                        output_dim=128, \n",
    "                        input_length=max_len, \n",
    "                        name='embed')(text_input)\n",
    "x = layers.Conv1D(32, 7, activation='relu')(x)\n",
    "x = layers.MaxPooling1D(5)(x)\n",
    "x = layers.Conv1D(32, 7, activation='relu')(x)\n",
    "x = layers.GlobalMaxPooling1D()(x)\n",
    "output = layers.Dense(1)(x)\n",
    "\n",
    "model = Model(  inputs=text_input, \n",
    "                outputs=output)\n",
    "model.summary()\n",
    "\n",
    "model.compile(  optimizer='rmsprop', \n",
    "                loss='binary_crossentropy', \n",
    "                metrics=['acc'])\n",
    "\n",
    "!mkdir my_log_dir\n",
    "\n",
    "callbacks = [\n",
    "    TensorBoard(log_dir='my_log_dir', histogram_freq=1, embeddings_freq=1)\n",
    "]\n",
    "\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=20,\n",
    "                    batch_size=128,\n",
    "                    validation_split=0.2,\n",
    "                    callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bef5fecf85687eca68836721658cd1e244cac69bf9704addfe1c1a98ab908ec0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('pv_forecast': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
